{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "- Create a Convolutional Neural Network for classifying nuts and bots\n",
    "- To learn the use of commonly used deep learning layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,\\\n",
    "Conv2D, MaxPooling2D, Permute, Reshape\n",
    "import skimage\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "#K.set_session('sess')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../data/nuts_n_bolts_master/all_dl/train'\n",
    "test_path = '../data/nuts_n_bolts_master/all_dl/test'\n",
    "val_path = '../data/nuts_n_bolts_master/all_dl/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "        val_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 50x65\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,  # this is the target directory\n",
    "        target_size=(50, 65),  # all images will be resized to 50x65\n",
    "        batch_size=batch_size,\n",
    "        classes = ['nuts','bolts'],\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a simple CNN model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a model in keras for nuts_and_bolts classfication\n",
    "# The model consists of two convolutional layers followed by Relu\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare 2 convolutional layers for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare rest of the network for the model\n",
    "- Add a maxpooling layer\n",
    "- Add two fully connected layer, the final fully connected layer will be the classifier output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Flatten())\n",
    "a,b,c,d = model.output_shape\n",
    "a = b * c * d\n",
    "model.add(Permute((1, 2, 3)))  # Indicate NHWC data layout\n",
    "model.add(Reshape((a,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 1.1023 - acc: 0.5639 - val_loss: 0.5864 - val_acc: 0.6316\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 4s 365ms/step - loss: 0.5544 - acc: 0.7284 - val_loss: 0.4016 - val_acc: 0.8421\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 4s 353ms/step - loss: 0.3951 - acc: 0.8315 - val_loss: 0.1913 - val_acc: 0.9211\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.3107 - acc: 0.8587 - val_loss: 0.2001 - val_acc: 0.9474\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.3335 - acc: 0.8697 - val_loss: 0.2549 - val_acc: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f280c2615f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 63, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 61, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 23, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 22080)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               2826368   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 2,836,770\n",
      "Trainable params: 2,836,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test score: 0.785666879447\n",
      "Test accuracy: 0.718487400655\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-660aa97d1a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# serialize model to JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mconstant_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'activation_4/Softmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstant_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"graph.pb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "\n",
    "sess = tensorflow.keras.backend.get_session()\n",
    "constant_graph = tf.graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), ['activation_4/Softmax'])\n",
    "tf.train.write_graph(constant_graph, \"\", \"graph.pb\", as_text=False)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"../models/nuts_and_bolts_dl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"../models/nuts_and_bolts_dl.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's increase the number of convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets test results for our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 9s 876ms/step - loss: 1.2440 - acc: 0.4740 - val_loss: 0.6934 - val_acc: 0.4737\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 0.6789 - acc: 0.6316 - val_loss: 0.6263 - val_acc: 0.9211\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 8s 792ms/step - loss: 0.6090 - acc: 0.7419 - val_loss: 0.4348 - val_acc: 0.8684\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 8s 802ms/step - loss: 0.4239 - acc: 0.8261 - val_loss: 0.2337 - val_acc: 0.8421\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 8s 800ms/step - loss: 0.2777 - acc: 0.8831 - val_loss: 0.2063 - val_acc: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f213d7d4518>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.512016474402\n",
      "Test accuracy: 0.815126048918\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets analyse the effect of adding a few drop out layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model to analyse if dropout increases accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 9s 892ms/step - loss: 0.7307 - acc: 0.4903 - val_loss: 0.6795 - val_acc: 0.4737\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 8s 809ms/step - loss: 0.5810 - acc: 0.6889 - val_loss: 0.3036 - val_acc: 0.9211\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 8s 832ms/step - loss: 0.9397 - acc: 0.6739 - val_loss: 0.4549 - val_acc: 0.7895\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 8s 828ms/step - loss: 0.4931 - acc: 0.7635 - val_loss: 0.4046 - val_acc: 0.8158\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 8s 833ms/step - loss: 0.3777 - acc: 0.8261 - val_loss: 0.2686 - val_acc: 0.8947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f213c876da0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test loss function and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.570904813112\n",
      "Test accuracy: 0.766806722814\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, steps=50)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_json = model.to_json()\n",
    "with open(\"../models/nuts_and_bolts_dl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"../models/nuts_and_bolts.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try out different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activations = ['relu','tanh','sigmoid']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to construct and evaluate a model to make the comparison of different loss functions easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_and_evaluate_model(actv):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(50,65,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(Conv2D(32,(3,3),activation= actv))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation= actv))\n",
    "    model.add(Dense(2, activation= actv))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100 // batch_size,\n",
    "        epochs=2,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=100 // batch_size)\n",
    "    score = model.evaluate_generator(test_generator, steps=50)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVATION relu \n",
      "\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 9s 881ms/step - loss: 1.3191 - acc: 0.5517 - val_loss: 0.6931 - val_acc: 0.4737\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 8s 801ms/step - loss: 0.6931 - acc: 0.5216 - val_loss: 0.6931 - val_acc: 0.5263\n",
      "Test score: 0.693147182465\n",
      "Test accuracy: 0.550420175612\n",
      "1 loop, best of 1: 23.3 s per loop\n",
      "\n",
      "\n",
      "ACTIVATION tanh \n",
      "\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 9s 884ms/step - loss: 1.0280 - acc: 0.5639 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 8s 801ms/step - loss: 0.6931 - acc: 0.5407 - val_loss: 0.6931 - val_acc: 0.4474\n",
      "Test score: 0.693147182465\n",
      "Test accuracy: 0.544117653946\n",
      "1 loop, best of 1: 23.3 s per loop\n",
      "\n",
      "\n",
      "ACTIVATION sigmoid \n",
      "\n",
      "Epoch 1/2\n",
      "10/10 [==============================] - 9s 884ms/step - loss: 1.9768 - acc: 0.4361 - val_loss: 1.8768 - val_acc: 0.4474\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 8s 805ms/step - loss: 1.7619 - acc: 0.4211 - val_loss: 1.3723 - val_acc: 0.5000\n",
      "Test score: 1.49803520376\n",
      "Test accuracy: 0.451680680972\n",
      "1 loop, best of 1: 23.7 s per loop\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for actv in activations:\n",
    "    print('ACTIVATION',actv,'\\n')\n",
    "    %timeit -n1 -r1 build_and_evaluate_model(actv)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/senthil/.virtualenvs/sc/lib/python3.4/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file <_io.BufferedReader name='../data/nuts_n_bolts_master/all_dl/test/bolts/.DS_Store'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-69b320408f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/senthil/.virtualenvs/sc/lib/python3.4/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_grey, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/senthil/.virtualenvs/sc/lib/python3.4/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                                (plugin, kind))\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/senthil/.virtualenvs/sc/lib/python3.4/site-packages/skimage/io/_plugins/pil_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/senthil/.virtualenvs/sc/lib/python3.4/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2348\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2349\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file <_io.BufferedReader name='../data/nuts_n_bolts_master/all_dl/test/bolts/.DS_Store'>"
     ]
    }
   ],
   "source": [
    "bolt_path = '../data/nuts_n_bolts_master/all_dl/test/bolts/'\n",
    "nut_path = '../data/nuts_n_bolts_master/all_dl/test/nuts'\n",
    "image_paths = [os.path.join(bolt_path, img_name) for img_name in os.listdir(bolt_path)]\n",
    "image_paths += [os.path.join(nut_path, img_name) for img_name in os.listdir(nut_path)]\n",
    "test_images = np.zeros((len(image_paths),50,65,3))\n",
    "\n",
    "for ind,image_name in enumerate(image_paths):\n",
    "    test_images[ind, :, :, :] = resize(imread(image_name), (50,65,3))\n",
    "    \n",
    "prediction = model.predict(test_images)\n",
    "labels = ['nuts' if img_pred[0] > img_pred[1] else 'bolts' for img_pred in prediction]\n",
    "image_names = [os.path.basename(path) for path in image_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Display all nuts image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pred in labels:\n",
    "  if pred == 'nuts':\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[ind,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display all bolt images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  if pred == 'bolts':\n",
    "    plt.figure()\n",
    "    plt.imshow(test_images[ind,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
