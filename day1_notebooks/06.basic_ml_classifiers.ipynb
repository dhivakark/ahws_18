{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io, color, transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size, padding=255):\n",
    "    '''\n",
    "    Resize the given image to specified size\n",
    "    Inputs:\n",
    "        img = Image to be resized (Numpy NDArray)\n",
    "        size = Scalar value. Image will be resized to (size, size)\n",
    "    Returns:\n",
    "        reszd_img = Resized image (Numpy NDArray)\n",
    "    '''\n",
    "    # Append zeros or ones based on the choice of padding\n",
    "    # to maintain the aspect ratio of the image\n",
    "    rows, cols = img.shape[:2]\n",
    "    max_size = max(rows, cols)\n",
    "    canvas = np.ones((max_size, max_size), np.uint8) * padding\n",
    "    \n",
    "    # Place the actual image at the center of the canvas\n",
    "    c_x, c_y = max_size / 2, max_size / 2\n",
    "    x_beg = max(0, int(c_x - (cols / 2)))\n",
    "    y_beg = max(0, int(c_y - (rows / 2)))\n",
    "    x_end, y_end = x_beg + cols, y_beg + rows\n",
    "    print(y_beg, x_beg, x_beg, x_end)\n",
    "    canvas[y_beg: y_end, x_beg: x_end] = img\n",
    "        \n",
    "    # Resize the image and write to op_dir_path specified\n",
    "    #reszd_img = transform.resize(canvas, (size, size))\n",
    "    reszd_img = cv2.resize(canvas, (size, size))\n",
    "    reszd_img = np.asarray(reszd_img, np.uint8)\n",
    "    # reszd_img = np.asarray(reszd_img * 255, np.uint8)\n",
    "    return reszd_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    '''\n",
    "    Extract the features from the Image\n",
    "    '''\n",
    "    gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = resize_image(gray_img, 250)\n",
    "    gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    \n",
    "    # Binarize the image using Adaptive thresholding\n",
    "    th, bin_img = cv2.threshold(gray_img, 250, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Close the holes by Morphological operations (Erosion and Dilation)\n",
    "    struct_elem = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "    smooth_bin_img = cv2.erode(bin_img, struct_elem, iterations=1)\n",
    "    smooth_bin_img = cv2.dilate(smooth_bin_img, struct_elem, iterations=2)\n",
    "    \n",
    "    # Find all the contours from the binary image\n",
    "    img, contours, heirarchy = cv2.findContours(smooth_bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the circularity\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    rect_area = w * h\n",
    "    contour_area = cv2.contourArea(contours[0])\n",
    "    circularity = contour_area / rect_area\n",
    "    \n",
    "    # Find the compactness\n",
    "    mask_img = np.zeros_like(smooth_bin_img)\n",
    "    mask_img = cv2.drawContours(mask_img, [contours[0]], -1, 255, -1)\n",
    "    white_mask_img = cv2.bitwise_and(smooth_bin_img, smooth_bin_img, mask=mask_img)\n",
    "    white_area = cv2.countNonZero(white_mask_img)\n",
    "    compactness = white_area / contour_area\n",
    "    \n",
    "    features = [circularity, compactness]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_from_imgs(data_dir, class_label):\n",
    "    '''\n",
    "    Read images from the data directory\n",
    "    Extract features from images and load that into array\n",
    "    '''\n",
    "    all_features = []\n",
    "    for img_name in os.listdir(data_dir):\n",
    "        img_path = path.join(data_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        img_features = extract_features(image)\n",
    "        img_features.append(class_label)\n",
    "        all_features.append(img_features)\n",
    "    all_features = np.array(all_features, np.float)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, X, y):\n",
    "    '''\n",
    "    Test the trained model with the test data\n",
    "    '''\n",
    "    pred_acc_list = []\n",
    "    for sample, label in zip(X, y):\n",
    "        pred = model.predict(sample.reshape(1, -1))[0]\n",
    "        pred_acc_list.append(int(pred) == int(label))\n",
    "    accuracy = sum(pred_acc_list) / float(len(pred_acc_list)) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 360\n",
      "0 0 0 500\n",
      "0 0 0 200\n",
      "0 0 0 300\n",
      "0 0 0 2100\n",
      "0 0 0 250\n",
      "0 0 0 750\n",
      "0 16 16 199\n",
      "0 3 3 224\n",
      "0 0 0 225\n",
      "0 0 0 225\n",
      "0 2 2 247\n",
      "0 0 0 1000\n",
      "0 0 0 500\n",
      "0 0 0 300\n",
      "0 0 0 250\n",
      "0 0 0 500\n",
      "3 0 0 300\n",
      "0 0 0 1000\n",
      "0 0 0 250\n",
      "40 0 0 386\n",
      "12 0 0 600\n",
      "0 0 0 2100\n",
      "0 0 0 250\n",
      "0 0 0 342\n",
      "0 0 0 330\n",
      "0 0 0 500\n",
      "0 0 0 400\n",
      "0 0 0 800\n",
      "40 0 0 386\n",
      "18 0 0 244\n",
      "0 0 0 450\n",
      "0 0 0 400\n",
      "57 0 0 1600\n",
      "0 0 0 1024\n",
      "0 0 0 250\n",
      "0 0 0 250\n",
      "0 0 0 276\n",
      "54 0 0 900\n",
      "0 0 0 400\n",
      "0 0 0 250\n",
      "0 0 0 300\n",
      "0 0 0 800\n",
      "0 0 0 2100\n",
      "0 0 0 250\n",
      "1 0 0 342\n",
      "125 0 0 573\n",
      "8 0 0 300\n",
      "0 0 0 450\n",
      "0 0 0 342\n",
      "0 22 22 422\n",
      "0 0 0 300\n",
      "0 3 3 345\n",
      "0 0 0 100\n",
      "22 0 0 248\n",
      "5 0 0 342\n",
      "0 0 0 250\n",
      "0 0 0 500\n",
      "0 0 0 500\n",
      "0 0 0 225\n",
      "5 0 0 1267\n",
      "0 0 0 281\n",
      "0 0 0 250\n",
      "89 0 0 423\n",
      "0 2 2 502\n",
      "36 0 0 264\n",
      "0 0 0 330\n",
      "0 0 0 500\n",
      "56 0 0 661\n",
      "0 0 0 100\n",
      "0 0 0 200\n",
      "0 0 0 250\n",
      "0 0 0 720\n",
      "74 0 0 444\n",
      "108 0 0 480\n",
      "0 1 1 319\n",
      "0 0 0 480\n",
      "0 0 0 500\n",
      "0 0 0 250\n",
      "62 0 0 374\n",
      "62 0 0 374\n",
      "0 0 0 250\n",
      "0 0 0 224\n",
      "34 0 0 381\n",
      "0 0 0 500\n",
      "151 0 0 600\n",
      "0 0 0 250\n",
      "0 0 0 225\n",
      "0 0 0 218\n",
      "0 0 0 1000\n",
      "0 0 0 300\n",
      "0 0 0 200\n",
      "0 4 4 495\n",
      "0 0 0 200\n",
      "0 0 0 224\n",
      "0 0 0 250\n",
      "62 0 0 374\n",
      "0 11 11 511\n",
      "120 0 0 960\n",
      "0 0 0 480\n",
      "0 0 0 174\n",
      "0 0 0 224\n",
      "4 0 0 229\n",
      "0 0 0 225\n",
      "0 0 0 300\n",
      "0 0 0 225\n",
      "0 7 7 349\n",
      "0 0 0 225\n",
      "0 0 0 250\n",
      "40 0 0 268\n",
      "18 0 0 244\n",
      "0 0 0 225\n",
      "0 0 0 250\n",
      "0 0 0 225\n",
      "26 0 0 252\n",
      "0 0 0 225\n",
      "0 2 2 198\n",
      "0 0 0 225\n",
      "0 0 0 225\n",
      "0 11 11 225\n",
      "0 0 0 225\n",
      "77 0 0 705\n",
      "0 0 0 200\n",
      "0 0 0 225\n",
      "21 0 0 247\n",
      "28 0 0 170\n",
      "54 0 0 285\n",
      "28 0 0 170\n",
      "28 0 0 170\n",
      "0 0 0 225\n",
      "5 0 0 230\n",
      "0 13 13 156\n",
      "47 0 0 277\n",
      "46 0 0 275\n",
      "28 0 0 450\n",
      "32 0 0 259\n",
      "0 31 31 139\n",
      "0 8 8 225\n",
      "46 0 0 450\n",
      "0 0 0 225\n",
      "0 0 0 225\n",
      "0 0 0 225\n",
      "0 0 0 225\n",
      "28 0 0 170\n",
      "28 0 0 170\n",
      "28 0 0 170\n",
      "46 0 0 275\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data/nuts_n_bolts_master/all_svm/'\n",
    "train_dir = path.join(data_dir, 'train')\n",
    "test_dir = path.join(data_dir, 'test')\n",
    "\n",
    "# Collect the Training and Test data\n",
    "nuts_class, bolts_class = 0, 1\n",
    "train_nuts_data = load_data_from_imgs(path.join(train_dir, 'nuts'), nuts_class)\n",
    "train_bolts_data = load_data_from_imgs(path.join(train_dir, 'bolts'), bolts_class)\n",
    "train_data = np.append(train_nuts_data, train_bolts_data, axis=0)\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "# Test data\n",
    "test_nuts_data = load_data_from_imgs(path.join(test_dir, 'nuts'), nuts_class)\n",
    "test_bolts_data = load_data_from_imgs(path.join(test_dir, 'bolts'), bolts_class)\n",
    "test_data = np.append(test_nuts_data, test_bolts_data, axis=0)\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "X, y = train_data[:, :2], train_data[:, 2]\n",
    "test_X, test_y = test_data[:, :2], test_data[:, 2]\n",
    "dec_tr_clf = tree.DecisionTreeClassifier()\n",
    "dec_tr_clf = dec_tr_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 89.36170212765957\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', test_model(dec_tr_clf, test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c4e49f9aed84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m dot_data = tree.export_graphviz(dec_tr_clf, out_file=None,\n\u001b[1;32m      3\u001b[0m                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'circularity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compactness'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nut'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bolt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import graphviz \n",
    "dot_data = tree.export_graphviz(dec_tr_clf, out_file=None,\n",
    "                                feature_names=['circularity', 'compactness'],\n",
    "                                class_names=['Nut', 'Bolt'],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"Nuts and Bolts\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nog2mAwMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b986a8b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_step = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "Z = dec_tr_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "plt.xlabel('Circularity')\n",
    "plt.ylabel('Compactness')\n",
    "target_names = ['Nut', 'Bolt']\n",
    "\n",
    "# Plot the training points\n",
    "for i, color in zip(range(2), 'rb'):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], c=color, label=target_names[i],\n",
    "                cmap=plt.cm.RdYlBu, edgecolor='black', s=20)\n",
    "plt.xlim([0.2, 1.2])\n",
    "plt.ylim([0.2, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "log_reg_clf = linear_model.LogisticRegression()\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "log_reg_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2) (100,)\n",
      "[ 0.79887486  0.96896243]\n",
      "(47,) (47,) (47,) (47, 2)\n",
      "38\n",
      "47\n",
      "80.85106382978724\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "#import cv2\n",
    "# svm_params = dict( kernel_type = cv2.SVM_LINEAR,\n",
    "#                    svm_type = cv2.SVM_C_SVC,\n",
    "#                    C=2.67, gamma=5.383 )\n",
    "# svm = cv2.SVM()\n",
    "# svm.train(X,Y, params=svm_params)\n",
    "# svm.save('svm_data.dat')\n",
    "# result = svm.predict_all(test_X)\n",
    "\n",
    "\n",
    "#svm = cv2.ml.SVM_create()\n",
    "#svm.setType(cv2.ml.SVM_C_SVC)\n",
    "#svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "#svm.setDegree(0.0)\n",
    "#svm.setGamma(0.0)\n",
    "#svm.setCoef0(0.0)\n",
    "#svm.setC(0)\n",
    "#svm.setNu(0.0)\n",
    "#svm.setP(0.0)\n",
    "#svm.setClassWeights(None)\n",
    "#svm.setTermCriteria((cv2.TERM_CRITERIA_COUNT, 100, 1.e-06))\n",
    "#rint(X,y)\n",
    "\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setGamma(5.383)\n",
    "svm.setC(2.67)\n",
    "svm.setTermCriteria((cv.TERM_CRITERIA_COUNT, 100, 1e-6))\n",
    "\n",
    "#X = np.asarray(X, dtype = np.float32).reshape(X.shape[0], 1, X.shape[1])\n",
    "X = np.asarray(X, dtype = np.float32)\n",
    "y = np.asarray(y, dtype = np.int32)\n",
    "test_X = np.asarray(test_X, dtype = np.float32)\n",
    "\n",
    "#X = np.matrix([[501, 10], [255, 10], [501, 255], [10, 501]], dtype=np.float32)\n",
    "#y = np.array([1, -1, -1, -1])\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print(X[0])\n",
    "svm.train(X, cv.ml.ROW_SAMPLE, y)\n",
    "_, result = svm.predict(test_X)\n",
    "#print(result)\n",
    "result = result.reshape(result.shape[0])\n",
    "mask = np.equal(result,test_y)\n",
    "print(mask.shape, result.shape, test_y.shape, test_X.shape)\n",
    "correct = len([1 for label in mask if label == True])\n",
    "print(correct)\n",
    "print(result.size)\n",
    "print(correct*100.0/result.size)\n",
    "svm.save('svm_data.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'SVM_load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b5523027f70f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVM_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./svm.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/senthil/Personal/workshop/ahws_17/examples/data/nuts_bolts_v1/bolt.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'SVM_load'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "svm = cv2.ml.SVM_load('./svm.dat')\n",
    "image = cv2.imread('/home/senthil/Personal/workshop/ahws_17/examples/data/nuts_bolts_v1/bolt.jpg')\n",
    "image_features = extract_features(image).reshape(1, image_features.shape[0])\n",
    "_, result = svm.predict(image_features)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy =  87.2340425531915\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy = ', test_model(log_reg_clf, test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe7425c19514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Plot the decision boundary. For that, we will assign a color to each\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# point in the mesh [x_min, x_max]x[y_min, y_max].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "h = .02  # step size in the mesh\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = log_reg_clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "# Plot also the training points\n",
    "y_clrs = ['r' if elem==0 else 'b' for elem in y]\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_clrs, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Circularity')\n",
    "plt.ylabel('Compactness')\n",
    "\n",
    "plt.xlim([0.1, 1.2])\n",
    "plt.ylim([0.2, 1.5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
